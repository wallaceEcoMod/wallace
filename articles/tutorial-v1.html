<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Wallace Ecological Modeling Application Vignette • wallace</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Wallace Ecological Modeling Application Vignette">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">wallace</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.1.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes">
<li><a class="dropdown-item" href="../articles/tutorial-v2.html">Tutorial Vignette v2</a></li>
    <li><a class="dropdown-item" href="../articles/tutorial-v2-esp.html">Tutorial Vignette v2 (ESP)</a></li>
    <li><a class="dropdown-item" href="../articles/module-addition.html">Module addition</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Archive</h6></li>
    <li><a class="dropdown-item" href="../articles/tutorial-v1.html">Tutorial Vignette v1</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Wallace Ecological Modeling Application Vignette</h1>
                        <h4 data-toc-skip class="author">Jamie M.
Kass</h4>
                        <h4 data-toc-skip class="author">Sarah I.
Meenan</h4>
                        <h4 data-toc-skip class="author">Gonzalo E.
Pinilla-Buitrago</h4>
                        <h4 data-toc-skip class="author">Cory Merow</h4>
                        <h4 data-toc-skip class="author">Robert P.
Anderson</h4>
            
            <h4 data-toc-skip class="date">06/08/2018; updated
07/12/18</h4>
      

      <div class="d-none name"><code>tutorial-v1.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="preface">Preface<a class="anchor" aria-label="anchor" href="#preface"></a>
</h2>
<p>This vignette was written for <em>Wallace</em> v. 1.0.5, so if you
are using a different version, some things may not match up.
Additionally, we anticipate that this vignette and any others in the
<code>wallace</code> package will be updated regularly in accordance
with ongoing development.</p>
</div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><em>Wallace</em> is an <code>R</code>-based GUI application for
ecological modeling that currently focuses on building, evaluating, and
visualizing models of species niches and distributions. We will refer to
these models as species distribution models (SDMs), and we will not
explain them at length here—as you read through, you will be pointed to
some sources of detailed info within the application for reference.</p>
<p><em>Wallace</em> has many qualities which we think make it a good
example of next-generation scientific software: it’s 1) open, 2)
expandable, 3) flexible, 4) interactive, 5) instructive, and 6)
reproducible. The application features a pannable/zoomable map and
dynamic plots and tables. Data for the models can be downloaded from
online databases or uploaded by the user. Most results can be
downloaded, including the option to save R code that can reproduce your
analysis. For more details, including on SDMs, please see our <a href="https://doi.org/10.1111/2041-210X.12945" class="external-link">publication</a> in
<em>Methods in Ecology and Evolution</em>. The citation is below:</p>
<p>Kass JM, Vilela B, Aiello-Lammens ME, Muscarella R, Merow C, Anderson
RP. (2018). <em>Wallace</em>: A flexible platform for reproducible
modeling of species niches and distributions built for community
expansion. <em>Methods in Ecology and Evolution</em>. 9:1151-1156. <a href="DOI:10.1111/2041-210X.12945" class="uri">DOI:10.1111/2041-210X.12945</a></p>
<p>The <em>Wallace</em> project’s <a href="https://wallaceecomod.github.io/" class="external-link">main page</a> has links to the
<a href="https://groups.google.com/forum/#!forum/wallaceecomod" class="external-link">Google
Group</a>, the official <a href="mailto:wallaceecomod@gmail.com">email</a>, the <a href="https://CRAN.R-project.org/package=wallace" class="external-link">CRAN page</a> hosting
the stable version, and the <a href="https://github.com/wallaceEcoMod/wallace" class="external-link">Github development
page</a>.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>For <code>wallace</code> to work, <strong>you should be using the
latest version of R</strong> (or at least later than version 3.2.1).
Download for <a href="https://cran.r-project.org/bin/windows/base/" class="external-link">Windows</a> or <a href="https://cran.r-project.org/bin/macosx/" class="external-link">Mac</a>.</p>
<p>Let’s first install and load <em>Wallace</em>. Open either the base
<code>R</code> software or RStudio and run the code below. It’s the only
code you’ll have to run to use Wallace.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install the package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">'wallace'</span><span class="op">)</span></span>
<span><span class="co"># load the package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="http://wallaceecomod.github.io/wallace/">wallace</a></span><span class="op">)</span></span>
<span><span class="co"># run the app</span></span>
<span><span class="fu"><a href="../reference/run_wallace.html">run_wallace</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>The <em>Wallace</em> GUI will open in your default web browser and
the <code>R</code> console will be occupied. You can exit
<em>Wallace</em> by hitting <code>Escape</code> while in the
<code>R</code> console, or by closing the browser window. A note: if you
close the browser window running <em>Wallace</em>, <strong>your session
will be over and all progress will be lost</strong>.</p>
<p><img src="vignette_img/v1/0_a_intro.jpg" width="800px"></p>
<p>If you’d like to use the <code>R</code> console while running
<em>Wallace</em>, open a terminal window (MacOS/Linux) or command prompt
(Windows), initialize <code>R</code>, and then run the lines above. An
example with Terminal in MacOS is below.</p>
<p><img src="vignette_img/v1/0_b_intro.jpg" width="800px"></p>
<p>Also, if you’d like to use Maxent in <em>Wallace</em>, please note
the following. <em>Wallace</em> uses the <code>maxent()</code> function
in the package <code>dismo</code>. This function requires the user to
place the <code>maxent.jar</code> file in the <code>/java</code>
directory of the <code>dismo</code> package root folder. You can
download Maxent
<a href="https://biodiversityinformatics.amnh.org/open_source/maxent/" target="_blank" class="external-link">here</a>,
and locate <code>maxent.jar</code>, which is the Maxent program itself,
in the downloaded folder. You can find the directory path to
<code>dismo/java</code> by running
<code>system.file('java', package="dismo")</code> at the R console.
Simply copy <code>maxent.jar</code> and paste it into this folder. If
you try to run Maxent in <em>Wallace</em> without the file in place, you
will get a warning message in the log window that informs you what to
do, but Maxent will not run. Also, if you have trouble installing
<code>rJava</code> and making it work, there is a bit of troubleshooting
on the <em>Wallace</em> Github repository
<a href="https://github.com/wallaceEcoMod/wallace" target="_blank" class="external-link">README</a>
that hopefully should help.</p>
</div>
<div class="section level2">
<h2 id="orientation">Orientation<a class="anchor" aria-label="anchor" href="#orientation"></a>
</h2>
<p>We’ll begin with the “Obtain Occurrence Data” component, but first a
little orientation. Please consult the schematic below showing the
different parts of <em>Wallace</em>.</p>
<p><img src="vignette_img/v1/0_c_intro.jpg" width="800px"></p>
<p>You will notice tabs along the top of the <em>Wallace</em> interface:
these are “components”, which represent discrete steps of the analysis,
and you will be stepping sequentially through them (<em>1</em>). First,
click on “Occ Data”. On the left side, there is a toolbar with all the
user interface controls, like buttons, text inputs, etc. (<em>2</em>).
You can see that the “module” called <em><strong>Query
Database</strong></em> is currently selected. “Modules” are discrete
analysis options within each component, and can be contributed by other
researchers. You’ll see that another module exists for this component:
<em><strong>User-specified Occurrences</strong></em>. This module lets
you upload your own occurrence data. Try choosing this module instead
and notice that the toolbar changes, then click back to
<em><strong>Query Database</strong></em>. Within this toolbar, you can
find the module name and the <code>R</code> packages it uses
(<em>2a</em>) and the control panel for the selected module
(<em>2b</em>).</p>
<p>On the right side is the visualization space (<em>3</em>), which has
a log window (<em>3a</em>) and several tabs, including an interactive
map, occurrence records table, results window, and guidance text windows
for both the component and module levels (<em>3b</em>).</p>
<p>At this stage of the analysis, no results exist, and you have no data
yet for the table, but you can view the guidance text now. This text was
written by the developers to prepare users for each component and module
<em>methodologically</em> (what the tools do) and <em>theoretically</em>
(why we should use them). The guidance text also references scientific
papers from the ecology literature for more detailed reading. Please get
into the habit of consulting these before undertaking analyses, as they
should give you a more solid foundation for moving forward.</p>
</div>
<div class="section level2">
<h2 id="obtain-occurrence-data">Obtain Occurrence Data<a class="anchor" aria-label="anchor" href="#obtain-occurrence-data"></a>
</h2>
<p>Begin by clicking on the guidance text first for the component
<strong>Obtain Occurrence Data</strong>, and then for the modules. Let’s
read through these to get a better understanding of what is involved in
obtaining occurrence data, and how <em>Wallace</em> implements it.</p>
<p><img src="vignette_img/v1/1_a_occ_data.jpg" width="800px"></p>
<p><img src="vignette_img/v1/1_b_occ_data.jpg" width="800px"></p>
<p>Now that we’ve educated ourselves, let’s proceed to getting our
occurrences. As an example, let’s download occurrence records for
<em>Tremarctos ornatus</em> (spectacled bear) from GBIF. This is a
species of concern
<a href="https://www.iucnredlist.org/species/22066/123792952" target="_blank" class="external-link">listed
as “vulnerable” by the IUCN</a>, and has a range nicely delimited by the
northern and central Andes mountains. Set the maximum number of
occurrences to 200 and click the <strong>Query Database</strong> button.
After the download is complete, notice the message in the log window.
You searched for 200 records, but only found 66 records with coordinate
information (latitude, longitude) that were not duplicates. If you
wanted 200 or more records with this information that is crucial for
SDMs, you could increase the maximum occurrences you search for and try
again.</p>
<p><img src="vignette_img/v1/1_c_occ_data.jpg" width="800px"></p>
<p>Now click on the “Occs Tbl” tab to view more information on the
records. The developers chose the fields that are displayed based on
their general relevance to studies on species ranges. You can click the
<strong>Download</strong> button to get a .csv file of these records,
which has all the original database fields for every downloaded record
(before any filtering).</p>
<p><img src="vignette_img/v1/1_d_occ_data.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="process-occurrence-data">Process Occurrence Data<a class="anchor" aria-label="anchor" href="#process-occurrence-data"></a>
</h2>
<p>The next component, <strong>Process Occs</strong>, gives you access
to some data-cleaning tools. The data you downloaded is raw, and there
will almost always be some erroneous points. Some basic knowledge of the
species’ range can help us remove the most obvious errors. We see that
some occurrence points for <em>T. ornatus</em>, a South American species
mostly occupying the Andes mountains, fall in California, Japan, and
even off the coast of Africa and in the Antarctic. For databases like
GBIF that accumulate lots of data from various sources, there are
inevitably some dubious localities that may represent, for example, a
museum location instead of the coordinates associated with the specimen,
or have incorrect coordinates for some other reason. In order to
eliminate these obviously erroneous records, select the points you want
to keep for analysis by clicking on the module <em><strong>Select
Occurrences On Map</strong></em>. Click on the polygon icon on the map
and draw a polygon around the points found in South America.</p>
<p><img src="vignette_img/v1/2_a_process_occs.jpg" width="800px"></p>
<p>When you are done, click “Finish” on the polygon toolbar, then
<strong>Select Occurrences</strong>. The map will zoom to the points
you’ve selected.</p>
<p><img src="vignette_img/v1/2_b_process_occs.jpg" width="800px"></p>
<p>Alternatively, you can also remove occurrences by ID with the module
<em><strong>Remove Occurrences by ID</strong></em>. <em>Tremarctos
ornatus</em> typically inhabits mid- to high-elevation areas. By zooming
in a bit, you can see that some occurrence points are in lowland areas
and may have incorrect georeferences or fall beyond the species’
accepted range. <strong>Note</strong>: for this vignette, we will
disregard the possibility that these points represent true lowland
sightings of <em>T. ornatus</em>, but for the purposes of research,
these assumptions should not be made trivially and require
investigation. To remove these points, click them to find their unique
ID (“occID”) and geographic coordinates, then enter the ID and click
<strong>Remove Occurrence</strong> to remove it.</p>
<p><img src="vignette_img/v1/2_c_process_occs.jpg" width="800px"></p>
<p>Even after removing likely erroneous points, the points you have left
may be clustered due to sampling bias. This often leads to artifactually
inflated spatial autocorrelation, which can bias the environmental
signal for the occurrence data that the model will attempt to fit. For
example, there might be clustering of points near cities because the
data are mostly from citizen scientists, and most citizen scientists
live in and near cities. Or the points can cluster around roads because
the field biologists who took the data were either making observations
while driving or gained access to sites from these roads.</p>
<p>Let’s click on the module <em><strong>Spatial Thin</strong></em>.
This lets you attempt to reduce a presumed spatial bias by running a
spatial thinning function on the points to make sure they’re all a
defined distance from one another. We will use 10 km as an example.</p>
<p><img src="vignette_img/v1/2_d_process_occs.jpg" width="800px"></p>
<p>We are now left with 44 points for our analysis (yours may be
different). You can zoom in to see what the function did. Red points
were retained, and blue points were removed. You can also download the
processed occurrence dataset as .csv by clicking on the
<strong>Download</strong> button.</p>
<p><img src="vignette_img/v1/2_e_process_occs.jpg" width="800px"></p>
<p><img src="vignette_img/v1/2_f_process_occs.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="obtain-environmental-data">Obtain Environmental Data<a class="anchor" aria-label="anchor" href="#obtain-environmental-data"></a>
</h2>
<p>Next, you will need to obtain environmental variables for your
analysis. The values of the variables are extracted for our occurrence
points, and this information is provided to the model. This data is in
raster form, which simply means a big grid where each grid cell
specifies a value. Rasters can be displayed as surfaces on maps (we’ll
see this later).</p>
<p>Click on the component “Env Data”. The first module,
<em><strong>WorldClim Bioclims</strong></em>, lets you download climatic
data from <a href="http://www.worldclim.org/" class="external-link">WorldClim</a>, a global
climate database of interpolated climate surfaces derived from weather
station data at multiple resolutions. The coverage is better for areas
with more weather stations (especially in developed countries), and more
uncertainty exists in areas with fewer stations. The <a href="http://www.worldclim.org/bioclim" class="external-link">bioclim</a> variables are
summaries of temperature and precipitation that have been proposed to
have general biological significance.</p>
<p>Choose the <strong>2.5 arcmin</strong> bioclim variable resolution
and click the <strong>Load Env Data</strong> button. The first time you
use <em>Wallace</em> these data are downloaded to your hard drive; after
that they will simply be loaded from this local directory. Finer
resolutions will take longer to download. The finest resolution data
(<strong>30 arcsec</strong>) is served by tile, and thus the tile that
corresponds to the map center will be downloaded. In addition to
downloading the rasters, <em>Wallace</em> will also remove any
occurrence points with no environmental values (i.e., points that did
not overlap with the rasters). Notice the progress bar in the
bottom-right corner.</p>
<p><img src="vignette_img/v1/3_a_env_data.jpg" width="800px"></p>
<p>After the rasters have loaded the “Results” tab will display some
summary information about them (e.g. resolution, extent, cell number,
etc.).</p>
<p><img src="vignette_img/v1/3_b_env_data.jpg" width="800px"></p>
<p>Note that you have the option to specify a subset of the total
variables to use in the analysis.</p>
<p><img src="vignette_img/v1/3_c_env_data.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="process-environmental-data">Process Environmental Data<a class="anchor" aria-label="anchor" href="#process-environmental-data"></a>
</h2>
<p>Now you will need to choose the study extent for modeling. This will
define the region from which “background” points are drawn for model
fitting. Background points are meant to sample the total area available
to the study species. Methods like Maxent are known as
presence-background techniques because they compare the predictor
variable values at background points to those at the occurrence points.
In making decisions about the study extent, we want to avoid areas the
species has historically been unable to move to—for example, regions
beyond a barrier like a mountain range or large river that the species
cannot traverse. If you include these areas, it may send a false signal
to the model that these areas are not suitable. Please see the guidance
text for more details.</p>
<p>You can explore the different options for delineating the study
extent here. To begin, go to the module <em><strong>Select Study
Region</strong></em>. There are two steps here: 1) choosing the shape of
the study extent, and 2) sampling the background points. Under “Step 1”,
choose “Minimum convex polygon”, and set the study region buffer
distance to 1 degree. Click the <strong>Select</strong> button to plot
this shape on the map.</p>
<p><img src="vignette_img/v1/4_a_process_envs.jpg" width="800px"></p>
<p>Next, complete “Step 2”, which both clips the rasters by the study
extent and samples the background points. Set the number of background
points to 10,000 (bigger, more extensive, samples are better), and click
the <strong>Sample</strong> button. Notice via the arrow the progress
bar in the bottom-right corner.</p>
<p><img src="vignette_img/v1/4_b_process_envs.jpg" width="800px"></p>
<p>Click the <strong>Download</strong> button if you want a zip file of
the clipped rasters.</p>
<p><img src="vignette_img/v1/4_c_process_envs.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="partition-occurrences">Partition occurrences<a class="anchor" aria-label="anchor" href="#partition-occurrences"></a>
</h2>
<p>We have not built any models yet, but before we do, we will make
decisions on how to partition our data for evaluation. In order to
determine the strength of the model’s predictive ability, you
theoretically need independent data to validate it. When no independent
datasets exist, one solution is to partition your data into subsets that
we assume are independent of each other, then sequentially build a model
on all the subsets but one and evaluate this model on the left-out
subset. This is known as <em>k</em>-fold cross-validation (where
<em>k</em> is the total number of subsets), and it is quite prevalent in
statistics, especially the fields of machine learning and data science.
After this sequential model- building exercise is complete,
<em>Wallace</em> summarizes (averages) the statistics over all of the
partitions and then builds a model using <strong>all</strong> the
data.</p>
<p>There’s a whole literature on how to best partition data for
modeling. One option is to simply partition randomly, but with spatial
data we run the risk that the groups are not spatially independent of
each other. An arguably better option is to partition using spatial
blocking—for example, by drawing lines on a map to divide the data.
Spatial partitioning with <em>k</em>-fold cross-validation forces the
model to predict to regions that are distant from those used to train
the model. For <em>Tremarctos ornatus</em>, environmental conditions in
the Andes of Ecuador and southwestern Colombia may differ considerably
from conditions in southern Peru. If the model has accurate predictions
on average on withheld spatially partitioned data, it likely has good
transferability, which means it can transfer well to new values of
predictor variables (as distant areas are usually more environmentally
different than close areas). Please refer to the guidance text for more
details on all the types of partitioning offered in
<em>Wallace</em>.</p>
<p>Here’s an example of random <em>k</em>-fold, which randomly assigns
each point to a partition group. Here, <em>k</em> = 4.</p>
<p><img src="vignette_img/v1/5_a_partition_occs.jpg" width="800px"></p>
<p>Here’s an example of spatial blocking, which assigns each point to
one of 4 spatially separate partition groups.</p>
<p><img src="vignette_img/v1/5_b_partition_occs.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="model">Model<a class="anchor" aria-label="anchor" href="#model"></a>
</h2>
<p>We are now ready to build a model. For this vignette, we’ll use
Maxent, a machine learning method that can fit a range of functions to
patterns in the data, from simple (i.e. straight lines) to complex
(i.e. curvy). For more details on Maxent, please consult the guidance
text.</p>
<p>The example images show a more extensive modeling exercise, but in
the interest of time, let’s choose the following modeling options:</p>
<ul>
<li>Select L, LQ, and H feature classes. These are the shapes that can
be fit to the data:
<ul>
<li>L = Linear, e.g. temp + precip</li>
<li>Q = Quadratic, e.g. temp^2 + precip^2</li>
<li>H = Hinge, e.g. piecewise linear functions, like splines</li>
</ul>
</li>
<li>Select regularization multipliers between 1-3 with a step value of
1.
<ul>
<li>Regularization is a way to reduce model complexity.</li>
<li>Higher values = smoother, less complex models. Basically, all
predictor variable coefficients are shrunk progressively until some
reach 0, when they drop out of the model. Only those variables with the
greatest predictive contribution remain in the model.</li>
</ul>
</li>
</ul>
<p>The 3 feature class combinations (L, LQ, H) * 3 regularization
multipliers (1, 2, 3) = 9 models. The feature classes H will enable
substantial complexity in the response, so it takes a bit longer to run
than the simpler models.</p>
<p><img src="vignette_img/v1/6_a_model.jpg" width="800px"></p>
<p>The first time you run this, you may get an error message if the
Maxent software is not in the <code>dismo</code> package folder. The
<code>dismo</code> package is what <em>Wallace</em> uses to run Maxent
through <code>R</code>. Fortunately, if this is the case,
<em>Wallace</em> will notify you in the log window where you need to put
the file (maxent.jar). This is due to the particular way
<code>dismo</code> does things, and is out of our control. We are
however working on alternative ways to approach this. Download the file
via the link given and put it in the appropriate directory. Then click
<strong>Run</strong> again.</p>
<p>The results appear in two tables of evaluation statistics, allowing
comparison of the different models you just built. There should be 9
rows per table: one for each of the feature class / regularization
multiplier combinations you selected (the images here will have more).
In the first table, statistics from the models built from the 4
occurrence data partition groups are averaged—these are labeled with
“test”. In the second table, statistics from each of the 4 groups are
displayed separately.</p>
<p>How do we choose the “best” model? There is a mountain of literature
about this, and there is really no single answer. AUC and OR (omission
rate) were calculated using our partitions, and AIC was instead
calculated using the model prediction of the full calibration background
extent (and all of the thinned occurrence points). Although AIC does not
incorporate the cross-validation results, it does explicitly penalize
model complexity—models with more parameters tend to have a worse AIC
score. It’s really up to the user to decide, and the guidance text has
some references which should help you learn more.</p>
<p>For this vignette, we will use sequential criteria on
cross-validation results. First, we will prioritize models that did not
omit many of the occurrence points in the predicted area. Sort the
results table by “or.10p.avg”, or the 10 percentile training presence
threshold applied to testing data (see guidance text for details). In
our set of models, the model with the lowest or.10p.avg was H_1 (hinge
features and regularization multiplier of 1).</p>
<p><img src="vignette_img/v1/6_b_model.jpg" width="800px"></p>
<p>If there had been a tie we could for example have chosen the model
with the highest “auc.val.avg” (average test AUC), but in this case,
model H_1 had the lowest OR. When we examine test AUC for this model, we
see it is reasonably high relative to the other models.</p>
<p><img src="vignette_img/v1/6_c_model.jpg" width="800px"></p>
<p>You can also find the evaluation statistics for each individual
partition in the table below, in comparison to the one above that only
lists averages.</p>
<p><img src="vignette_img/v1/6_d_model.jpg" width="800px"></p>
<p>In our example, if we had chosen the model with the lowest AICc
score, we would have ended up with H_3.5. Take a moment to find the
model with the lowest AICc and compare it to the one you chose
above.</p>
</div>
<div class="section level2">
<h2 id="visualize">Visualize<a class="anchor" aria-label="anchor" href="#visualize"></a>
</h2>
<p>The module “Maxent Evaluation Plots” enables users to evaluate the
performance statistics across models. Below, see how regularization
multiplier affects average test omission rate (using 10 percentile
training presence threshold.)</p>
<p><img src="vignette_img/v1/7_a_visualize.jpg" width="800px"></p>
<p>We should also examine the <strong>response curves</strong>, which
show how the predicted suitability (y-axis) changes based on different
values of each variable (x-axis). If you want to see the results for a
particular model, you can select it by using the dropdown menu under
“Current Model”. Below is one of the response curves for model H_1, mean
temperature of the wettest quarter (bio8). The flat portion of the
response curve indicates that suitability remains stable for lower
temperatures, but above 20 degrees C (the WorldClim values are
multiplied by 10, so 200 deg C on the x-axis is really 20 deg C),
suitability for <em>T. ornatus</em> decreases sharply.</p>
<p><img src="vignette_img/v1/7_b_visualize.jpg" width="800px"></p>
<p>You can also visualize model predictions on the map. Predictions of
suitability can be continuous (a range of values) or binary (thresholded
to just two values: 0 and 1). Please see the module guidance for
information about Maxent model output scales and thresholding rules.
Below is the mapped prediction for model H_1, no threshold.</p>
<p><img src="vignette_img/v1/7_c_visualize.jpg" width="800px"></p>
<p>Below is the mapped prediction of the same model, this time with the
threshold set to 10 percentile training presence. This is the stricter
of the two thresholding rules currently available. Some of the
occurrence points may fall outside the blue areas that represent
suitable areas for <em>T. ornatus</em>. This thresholded prediction was
used to calculate the 10 percentile training presence omission rate from
the evaluation statistics. Try mapping the prediction with the threshold
set to the less strict minimum training presence instead, and notice the
difference.</p>
<p><img src="vignette_img/v1/7_d_visualize.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="project">Project<a class="anchor" aria-label="anchor" href="#project"></a>
</h2>
<p>Next, you can project the model to new locations and future climate
scenarios (for years 2050 and 2070). “Projecting” simply means plugging
in new environmental values to the model (i.e., those not used for model
building) and getting a new response (i.e., suitability predictions for
new variable ranges).</p>
<p>This is potentially confusing – didn’t the cross-validation step do
this too? The cross-validation with spatial partitioning sequentially
forced models to predict to new areas, and the evaluation statistics
summarized their ability to transfer accurately. However, the final
model that we used to make the predictions we are currently looking at
was built with <strong>all</strong> the data (it did not exclude any
partition groups). So the variable ranges associated with all of the
background points in our dataset were used in the model-building
process.</p>
<p>We are now taking this model and projecting it to variable ranges
that were potentially never used in model-building. Thus, these values
for different places and times might be completely new to our model, and
could be so different that we may be uncertain in the accuracy of our
projection. Please see the guidance text for details on these
“non-analog conditions”.</p>
<p>H_1 has a low omission rate (so it rarely fails to predict known
occurrences) and a high average testing AUC (so it should have good
transferability). Below, model H_1 has been projected to the year 2070
under a severe climate scenario: representative concentration pathway
(RCP) 8.5. Notice also that there are several global circulation models
(GCMs) to choose from—these all represent different efforts to model
future climate. We used CCSM4 for this tutorial. See the module guidance
text for more on RCPs and GCMs.</p>
<p>To project your model, draw a polygon using the draw toolbar and
click “Finish”. Then choose a year, GCM and RCP and click the
<strong>Project</strong> button to build the new map. The rasters come
from the WorldClim database, and not all GCMs have raster data for each
RCP. Below is the continuous prediction. For our example, note that the
northernmost suitable area in the present seems to be contracted
southward, that suitability seems lower overall, and that it also
becomes more confined to higher elevations.</p>
<p><img src="vignette_img/v1/8_a_project.jpg" width="800px"></p>
<p>Below is the projection made binary by the 10 percentile training
presence threshold. We can see some of these differences between present
and future projection a bit more clearly now.</p>
<p><img src="vignette_img/v1/8_b_project.jpg" width="800px"></p>
<p>As we mentioned, there may be areas within our new ranges of values
that have high uncertainty because they are very different from the
values used in model-building. In order to visualize where these areas
are, we can plot a MESS map. MESS stands for (M)ultivariate
(E)nvironmental (S)imilarity (S)urface: please see the module guidance
text for details. Below is the MESS for our projection. All the darker
values correspond to areas similar to those used in model-building,
while the lighter ones are much more different. We can see that future
climate values at high elevation are similar, whereas those at lower
elevations west towards the coast are very different in some places,
especially in Colombia. We may therefore interpret that projected
suitability in these areas has high uncertainty.</p>
<p><img src="vignette_img/v1/8_c_project.jpg" width="800px"></p>
</div>
<div class="section level2">
<h2 id="extracting-the-code">Extracting the code<a class="anchor" aria-label="anchor" href="#extracting-the-code"></a>
</h2>
<p>A major advantage of <em>Wallace</em> compared to other GUI-based
software is that you can extract all the code used to run the analysis.
While we were using <em>Wallace</em>, lots of <code>R</code> code has
been running in the background. This option allows you to download a
simplified version of all that code in the form of a condensed and
annotated <code>R</code> script. You can use this script to rerun the
analysis session, share it, or modify it. The script can be downloaded
in several ways, but the <strong>R Markdown</strong> format, which is a
convenient format for combining <code>R</code> code and text, can be run
directly in <code>R</code>. For .pdf downloads, some version of TeX is
necessary to be installed on your system. Please see the text on this
page for more details.</p>
<p>To download the script, select Rmd and click Download.</p>
<p><img src="vignette_img/v1/rmd_1.jpg" width="800px"></p>
<p>Now, you should have an .Rmd file that contains your complete
analysis. <strong>R Markdown</strong> files combine regular text with
<strong>code chunks</strong>. Modules from <em>Wallace</em> are
indicated as headers denoted by <strong>###</strong>. For a quick
reference to Rmd syntax, see <a href="https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf" class="external-link">here</a></p>
<p><img src="vignette_img/v1/rmd_2.jpg" width="800px"></p>
<p>You might want to open a new R window and try running some of this
code. Remember that later sections of code may depend on things that
were done earlier, so they may not all run if you skip ahead. Also
remember that if you close your <em>Wallace</em> session you’ll lose
your progress in the web browser (but your .Rmd will be unaffected). If
you use RStudio, you can open this Rmd and click <strong>knit</strong>
to compile your workflow into a sharable html document.</p>
<p>Note that you can change anything you like in this code to build upon
your workflow. We envision that future versions of <em>Wallace</em> will
enable you to upload such modified .Rmds to <em>Wallace</em> to fill in
all the options you chose and pick up where you left off in a previous
analysis in the GUI.</p>
<p>Also, although we don’t have anything built into <em>Wallace</em> for
post-processing models in the present version, you can work in
<code>R</code> after the session by modifying the .Rmd and build on the
analysis. Examples of post-processing are stacking models to get
estimates of species richness, or comparing models to estimate niche
overlap. We are currently working with partners who specialize in this,
and future versions of <em>Wallace</em> will likely include capabilities
to engage in post-processing of models.</p>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>Thus ends the <em>Wallace</em> vignette. We hope you learned more
about the application, its features, and modeling of species
distributions and niches in general. We hate to be repetitive, but we
highly encourage you to read the guidance text, follow up on the
recommended publications, and hopefully let those lead you to other
relevant publications that can inform you further.</p>
<p>Also, please reach out to us by email or through any of the websites
mentioned in the Introduction. We’d love to hear your thoughts,
opinions, or suggestions on how to make <em>Wallace</em> better for all
users.</p>
</div>
<div class="section level2">
<h2 id="acknowledgments">Acknowledgments<a class="anchor" aria-label="anchor" href="#acknowledgments"></a>
</h2>
<p><em>Wallace</em> was recognized as a finalist for the 2015 Ebbe
Nielsen Challenge of the Global Biodiversity Information Facility
(GBIF), and received prize funding.</p>
<p>This material is based upon work supported by the National Science
Foundation under Grant Numbers DBI-1661510 (RPA), DBI-1650241 (RPA),
DEB-1119915 (RPA), DEB-1046328 (MEA), and DBI-1401312 (RM). Any
opinions, findings, and conclusions or recommendations expressed in this
material are those of the author(s) and do not necessarily reflect the
views of the National Science Foundation.</p>
<p>Additional sources of funding for JMK include a CUNY Science
Scholarship and a CUNY Graduate Center Provost Digital Innovation
Grant.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Bethany A. Johnson, Jamie M. Kass, Gonzalo E. Pinilla-Buitrago, Andrea Paz, Valentina Grisales-Betancur, Dean Attali, Matthew E. Aiello-Lammens, Cory Merow, Mary E. Blair, Robert P. Anderson.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
